{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the CRISP-DM Manual: \n",
    "This initial phase focuses on understanding the project objectives and requirements from a business perspective, then converting this knowledge into a data mining problem definition and a preliminary plan designed to achieve the objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Determine Business Objectives:*\n",
    "* Understand what makes cars more or less expensive. In other words, determine what features of a car contribute to that car's increase or decrease in value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Assess Situation:*\n",
    "* Resources: We have a Kaggle dataset with data on 426k used cars. We will investigate it in the Data Understanding Section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Determine Data Mining Goals:*\n",
    "* Data Mining Goals:\n",
    "    * Create models that can demonstrate the relationship between features of cars and the value of those cars in order to investigate how the features correlate with the values.\n",
    "* Data Mining Success Criteria:\n",
    "    * Find factors which contribute to value of each car. Determine to what degree they do and how (i.e., do they increase or decrease value, and at what rate?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Produce Project Plan:*\n",
    "* Project Plan: Fine tune the data for our models, then progressively try models until we can come away with actionable information for used car sales personnel to adequately assess inventory to maximize the potential of their sales. **In other words, how to determine the most valuable features that determine the price of their cars.**\n",
    "\n",
    "\n",
    "* Initial Assessment (of Tools, and Techniques): Dataset needs to be prepared for our analysis, changing . We are aware of techniques such as linear regression, sequential feature selection, and regularization which can help us make actionable conclusions as to what features are most important in determining the price of a car.\n",
    "* For numeric entries, we can use multidimensional forms of analysis like sequential feature selection or ridge regression, and use standardization to account for the differences between these features' magnitude\n",
    "* For non-numeric entries, we can consider creating dummy encoded versions of any given column and using LinearRegression to determine how a certain value in that column predicts price. We will come away with an understanding of how certain aspects of a car can be used to determine the price of that car.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can determine what features of the cars are likely to be useful, and which may not matter in our analysis.\n",
    "* find nans - consider clearing nans\n",
    "* note which columns are useful, which are useless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing data reveals that there are many duplicates, and many entries which are missing data in columns which could be crucial for analysis, those of which ought to be dropped during preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature analysis***\n",
    "* By analyzing the columns, we can anticipate which features of our vehicles will be helpful for predicting price and which may be arbitrary.\n",
    "* Year, Manufacturer, Condition, Cylinder, Fuel, Odomoter, Transmission, Type, Paint_color may all reliably contribute to price\n",
    "* Region may be analyzed, but may not be useful\n",
    "* Size is missing many values, and may be worth dropping\n",
    "* VIN is arbitrary and can be dropped for analysis\n",
    "* ID is arbitrary, but can be used for our index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***General possible integrity issues***\n",
    "* integrity issues - nans, numbered and non-numbered, duplicates\n",
    "* considerations - useful vs. non-useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                             region  price    year manufacturer  \\\n",
       "id                                                               \n",
       "7222695916                prescott   6000     NaN          NaN   \n",
       "7218891961            fayetteville  11900     NaN          NaN   \n",
       "7221797935            florida keys  21000     NaN          NaN   \n",
       "7222270760  worcester / central MA   1500     NaN          NaN   \n",
       "7210384030              greensboro   4900     NaN          NaN   \n",
       "...                            ...    ...     ...          ...   \n",
       "7301591192                 wyoming  23590  2019.0       nissan   \n",
       "7301591187                 wyoming  30590  2020.0        volvo   \n",
       "7301591147                 wyoming  34990  2020.0     cadillac   \n",
       "7301591140                 wyoming  28990  2018.0        lexus   \n",
       "7301591129                 wyoming  30590  2019.0          bmw   \n",
       "\n",
       "                               model condition    cylinders    fuel  odometer  \\\n",
       "id                                                                              \n",
       "7222695916                       NaN       NaN          NaN     NaN       NaN   \n",
       "7218891961                       NaN       NaN          NaN     NaN       NaN   \n",
       "7221797935                       NaN       NaN          NaN     NaN       NaN   \n",
       "7222270760                       NaN       NaN          NaN     NaN       NaN   \n",
       "7210384030                       NaN       NaN          NaN     NaN       NaN   \n",
       "...                              ...       ...          ...     ...       ...   \n",
       "7301591192         maxima s sedan 4d      good  6 cylinders     gas   32226.0   \n",
       "7301591187  s60 t5 momentum sedan 4d      good          NaN     gas   12029.0   \n",
       "7301591147          xt4 sport suv 4d      good          NaN  diesel    4174.0   \n",
       "7301591140           es 350 sedan 4d      good  6 cylinders     gas   30112.0   \n",
       "7301591129  4 series 430i gran coupe      good          NaN     gas   22716.0   \n",
       "\n",
       "           title_status transmission                VIN drive size       type  \\\n",
       "id                                                                              \n",
       "7222695916          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7218891961          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7221797935          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7222270760          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7210384030          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "...                 ...          ...                ...   ...  ...        ...   \n",
       "7301591192        clean        other  1N4AA6AV6KC367801   fwd  NaN      sedan   \n",
       "7301591187        clean        other  7JR102FKXLG042696   fwd  NaN      sedan   \n",
       "7301591147        clean        other  1GYFZFR46LF088296   NaN  NaN  hatchback   \n",
       "7301591140        clean        other  58ABK1GG4JU103853   fwd  NaN      sedan   \n",
       "7301591129        clean        other  WBA4J1C58KBM14708   rwd  NaN      coupe   \n",
       "\n",
       "           paint_color state  \n",
       "id                            \n",
       "7222695916         NaN    az  \n",
       "7218891961         NaN    ar  \n",
       "7221797935         NaN    fl  \n",
       "7222270760         NaN    ma  \n",
       "7210384030         NaN    nc  \n",
       "...                ...   ...  \n",
       "7301591192         NaN    wy  \n",
       "7301591187         red    wy  \n",
       "7301591147       white    wy  \n",
       "7301591140      silver    wy  \n",
       "7301591129         NaN    wy  \n",
       "\n",
       "[426880 rows x 17 columns]>"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vehicles = pd.read_csv('data/vehicles.csv', index_col=0)\n",
    "vehicles.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                             region  price    year manufacturer  \\\n",
       "id                                                               \n",
       "7222695916                prescott   6000     NaN          NaN   \n",
       "7218891961            fayetteville  11900     NaN          NaN   \n",
       "7221797935            florida keys  21000     NaN          NaN   \n",
       "7222270760  worcester / central MA   1500     NaN          NaN   \n",
       "7210384030              greensboro   4900     NaN          NaN   \n",
       "...                            ...    ...     ...          ...   \n",
       "7301591192                 wyoming  23590  2019.0       nissan   \n",
       "7301591187                 wyoming  30590  2020.0        volvo   \n",
       "7301591147                 wyoming  34990  2020.0     cadillac   \n",
       "7301591140                 wyoming  28990  2018.0        lexus   \n",
       "7301591129                 wyoming  30590  2019.0          bmw   \n",
       "\n",
       "                               model condition    cylinders    fuel  odometer  \\\n",
       "id                                                                              \n",
       "7222695916                       NaN       NaN          NaN     NaN       NaN   \n",
       "7218891961                       NaN       NaN          NaN     NaN       NaN   \n",
       "7221797935                       NaN       NaN          NaN     NaN       NaN   \n",
       "7222270760                       NaN       NaN          NaN     NaN       NaN   \n",
       "7210384030                       NaN       NaN          NaN     NaN       NaN   \n",
       "...                              ...       ...          ...     ...       ...   \n",
       "7301591192         maxima s sedan 4d      good  6 cylinders     gas   32226.0   \n",
       "7301591187  s60 t5 momentum sedan 4d      good          NaN     gas   12029.0   \n",
       "7301591147          xt4 sport suv 4d      good          NaN  diesel    4174.0   \n",
       "7301591140           es 350 sedan 4d      good  6 cylinders     gas   30112.0   \n",
       "7301591129  4 series 430i gran coupe      good          NaN     gas   22716.0   \n",
       "\n",
       "           title_status transmission                VIN drive size       type  \\\n",
       "id                                                                              \n",
       "7222695916          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7218891961          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7221797935          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7222270760          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "7210384030          NaN          NaN                NaN   NaN  NaN        NaN   \n",
       "...                 ...          ...                ...   ...  ...        ...   \n",
       "7301591192        clean        other  1N4AA6AV6KC367801   fwd  NaN      sedan   \n",
       "7301591187        clean        other  7JR102FKXLG042696   fwd  NaN      sedan   \n",
       "7301591147        clean        other  1GYFZFR46LF088296   NaN  NaN  hatchback   \n",
       "7301591140        clean        other  58ABK1GG4JU103853   fwd  NaN      sedan   \n",
       "7301591129        clean        other  WBA4J1C58KBM14708   rwd  NaN      coupe   \n",
       "\n",
       "           paint_color state  \n",
       "id                            \n",
       "7222695916         NaN    az  \n",
       "7218891961         NaN    ar  \n",
       "7221797935         NaN    fl  \n",
       "7222270760         NaN    ma  \n",
       "7210384030         NaN    nc  \n",
       "...                ...   ...  \n",
       "7301591192         NaN    wy  \n",
       "7301591187         red    wy  \n",
       "7301591147       white    wy  \n",
       "7301591140      silver    wy  \n",
       "7301591129         NaN    wy  \n",
       "\n",
       "[370678 rows x 17 columns]>"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles = vehicles.drop_duplicates()\n",
    "vehicles.head\n",
    "#We've dropped about 50k rows by dropping duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Too many NaNs for analysis***\n",
    "\n",
    "This dataset has plenty of NaNs in certain columns. Anything with a high number of NaN values should be omitted from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vehicles.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Deciding what to do***\n",
    "* We can remove size for having too many NaNs. If we parse away NaNs later, we might still be able to analyze certain columns like cylinders.\n",
    "* VIN is not useful\n",
    "* We should remove 'model', its entries are too specific.\n",
    "* Let's analyse some columns for usability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vehicles['title_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop size -- too many NaNs\n",
    "vehicles = vehicles.drop('size', axis=1)\n",
    "#Drop VIN, model, region -- not useful for analysis\n",
    "vehicles = vehicles.drop(['VIN','model','region','state'], axis=1)\n",
    "\n",
    "#Remove price == 0\n",
    "vehicles = vehicles[vehicles['price']!=0]\n",
    "vehicles = vehicles[vehicles['price']!=1]\n",
    "# vehicles.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vehicles['cylinders'].value_counts())\n",
    "cylinder_replacement_map = {'3 cylinders':3,'4 cylinders':4,'5 cylinders':5,'6 cylinders':6,'8 cylinders':8,'10 cylinders':10, '12 cylinders':12, 'other':''}\n",
    "vehicles = vehicles.replace({'cylinders' : cylinder_replacement_map})\n",
    "#drop empty value\n",
    "vehicles = vehicles[vehicles['cylinders']!='']\n",
    "#print new values\n",
    "# print(vehicles['cylinders'].dropna().value_counts())\n",
    "vehicles['cylinders'] = pd.to_numeric(vehicles['cylinders'])\n",
    "# numeric_columns = vehicles.select_dtypes('number').columns\n",
    "# print(f\"Numeric columns: {list(numeric_columns)}\")\n",
    "\n",
    "#Success!\n",
    "\n",
    "vehicles_num = vehicles.select_dtypes(include=np.number)\n",
    "# vehicles_num.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-numeric features: Single feature Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Manufacturer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    manufacturer           coef\n",
      "27          manufacturer_mercury    5876.729424\n",
      "36           manufacturer_saturn    7253.224707\n",
      "32          manufacturer_pontiac    8554.404192\n",
      "8          manufacturer_chrysler   11243.786842\n",
      "16            manufacturer_honda   11667.566560\n",
      "17          manufacturer_hyundai   12241.834633\n",
      "21              manufacturer_kia   12917.249017\n",
      "12             manufacturer_fiat   12984.507375\n",
      "30           manufacturer_morgan   13100.000000\n",
      "15  manufacturer_harley-davidson   13354.756757\n",
      "40       manufacturer_volkswagen   13438.250868\n",
      "25            manufacturer_mazda   13772.292089\n",
      "37           manufacturer_subaru   13911.915148\n",
      "29       manufacturer_mitsubishi   14862.913656\n",
      "22       manufacturer_land rover   15103.000000\n",
      "28             manufacturer_mini   15310.870518\n",
      "9            manufacturer_datsun   15757.200000\n",
      "10            manufacturer_dodge   17467.666731\n",
      "6          manufacturer_cadillac   20898.713694\n",
      "23            manufacturer_lexus   20903.060633\n",
      "0             manufacturer_acura   21402.309241\n",
      "24          manufacturer_lincoln   21474.505860\n",
      "18         manufacturer_infiniti   21724.399512\n",
      "31           manufacturer_nissan   22427.120810\n",
      "3              manufacturer_audi   25550.383063\n",
      "19           manufacturer_jaguar   27474.431503\n",
      "35            manufacturer_rover   29086.117816\n",
      "1        manufacturer_alfa-romeo   29392.085308\n",
      "4               manufacturer_bmw   30204.863674\n",
      "34              manufacturer_ram   30923.559586\n",
      "14              manufacturer_gmc   34170.521935\n",
      "33          manufacturer_porsche   34958.510150\n",
      "38            manufacturer_tesla   38645.388140\n",
      "5             manufacturer_buick   42622.210205\n",
      "13             manufacturer_ford   42804.325393\n",
      "2      manufacturer_aston-martin   65943.333333\n",
      "11          manufacturer_ferrari  130371.647887\n",
      "7         manufacturer_chevrolet  140909.894272\n",
      "20             manufacturer_jeep  189223.613764\n",
      "39           manufacturer_toyota  289159.372626\n",
      "41            manufacturer_volvo  440099.623932\n",
      "26    manufacturer_mercedes-benz  687891.210243\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(vehicles[['manufacturer']])\n",
    "# print(X.columns.to_list)\n",
    "y = vehicles['price']\n",
    "manu_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "# print(manu_linreg.coef_)\n",
    "manu_coef = pd.DataFrame({'manufacturer':list(X.columns),'coef':manu_linreg.coef_})\n",
    "# print(manu_coef)\n",
    "sorted_manu = manu_coef.sort_values(by='coef')\n",
    "print(sorted_manu)\n",
    "manu_mse = mean_squared_error(manu_linreg.predict(X),y)\n",
    "# print(manu_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Drive***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       drive           coef\n",
      "1  drive_fwd   17324.612954\n",
      "2  drive_rwd   45931.616868\n",
      "0  drive_4wd  138212.830207\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(vehicles[['drive']])\n",
    "\n",
    "y = vehicles['price']\n",
    "drive_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "\n",
    "drive_coef = pd.DataFrame({'drive':list(X.columns),'coef':drive_linreg.coef_})\n",
    "\n",
    "sorted_drive = drive_coef.sort_values(by='coef')\n",
    "print(sorted_drive)\n",
    "drive_mse = mean_squared_error(drive_linreg.predict(X),y)\n",
    "# print(drive_mse)\n",
    "var = np.var(y - drive_linreg.predict(X))\n",
    "# print(var)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Condition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  cond           coef\n",
      "5    condition_salvage    3736.608379\n",
      "4        condition_new   29779.991471\n",
      "2       condition_good   33613.216880\n",
      "3   condition_like new   42033.571666\n",
      "0  condition_excellent   62320.623768\n",
      "1       condition_fair  796604.879988\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(vehicles[['condition']])\n",
    "\n",
    "y = vehicles['price']\n",
    "cond_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "\n",
    "cond_coef = pd.DataFrame({'cond':list(X.columns),'coef':cond_linreg.coef_})\n",
    "\n",
    "sorted_cond = cond_coef.sort_values(by='coef')\n",
    "print(sorted_cond)\n",
    "mse = mean_squared_error(cond_linreg.predict(X),y)\n",
    "# print(mse)\n",
    "var = np.var(y - cond_linreg.predict(X))\n",
    "# print(var)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fuel***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            fuel           coef\n",
      "3    fuel_hybrid   15577.421172\n",
      "1  fuel_electric   26490.500000\n",
      "4     fuel_other   76943.532335\n",
      "2       fuel_gas   89552.846094\n",
      "0    fuel_diesel  149649.129281\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(vehicles[['fuel']])\n",
    "\n",
    "y = vehicles['price']\n",
    "fuel_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "\n",
    "fuel_coef = pd.DataFrame({'fuel':list(X.columns),'coef':fuel_linreg.coef_})\n",
    "\n",
    "sorted_fuel = fuel_coef.sort_values(by='coef')\n",
    "print(sorted_fuel)\n",
    "mse = mean_squared_error(fuel_linreg.predict(X),y)\n",
    "# print('mse: ', mse)\n",
    "var = np.var(y - fuel_linreg.predict(X))\n",
    "# print('var: ',var)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Title status***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              title status          coef\n",
      "5     title_status_salvage  10847.200115\n",
      "2     title_status_missing  11993.183060\n",
      "3  title_status_parts only  13648.404908\n",
      "4     title_status_rebuilt  15572.034870\n",
      "1        title_status_lien  22454.155684\n",
      "0       title_status_clean  95358.841552\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(vehicles[['title_status']])\n",
    "\n",
    "y = vehicles['price']\n",
    "title_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "\n",
    "title_coef = pd.DataFrame({'title status':list(X.columns),'coef':title_linreg.coef_})\n",
    "\n",
    "sorted_title = title_coef.sort_values(by='coef')\n",
    "print(sorted_title)\n",
    "mse = mean_squared_error(title_linreg.predict(X),y)\n",
    "# print('mse: ', mse)\n",
    "var = np.var(y - title_linreg.predict(X))\n",
    "# print('var: ',var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations -- Multidimensional Data\n",
    "Because the data we are using is multidimensional -- in other words, we'd like to know how multiple factors contribute together to affect the price of a vehicle, we will likely be using sequential feature selection or regularization for our eventual analysis. It appears we will be building linear regression models, and creating pipelines to fit our models to our data and then selecting the best model to represent our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model -- all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(fit_intercept=False)\n",
      "[-7.02542401e+01  3.58517492e+04  4.53417992e-02]\n",
      "187808051052264.94\n",
      "     feature          coef\n",
      "0       year    -70.254240\n",
      "1  cylinders  35851.749181\n",
      "2   odometer      0.045342\n"
     ]
    }
   ],
   "source": [
    "###Linear regression\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "vehicles_dropped = vehicles_num.dropna()\n",
    "X = pd.get_dummies(vehicles_dropped.drop('price', axis = 1))\n",
    "y = vehicles_dropped['price']\n",
    "all_features_linreg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "linreg_mse = mean_squared_error(all_features_linreg.predict(X), y)\n",
    "\n",
    "\n",
    "\n",
    "print(all_features_linreg)\n",
    "print(all_features_linreg.coef_)\n",
    "print(linreg_mse)\n",
    "\n",
    "feature_names = ('year','cylinders','odometer')\n",
    "linreg_df = pd.DataFrame({'feature': feature_names, 'coef': all_features_linreg.coef_})\n",
    "print(linreg_df)\n",
    "# vehicles_dropped.info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate train/test data for vehicles\n",
    "# vehicles =  vehicles.select_dtypes(include=np.number).dropna()\n",
    "v_dropped = vehicles_num.dropna()\n",
    "vehicles_X = v_dropped.drop(['price'], axis = 1)\n",
    "vehicles_y = v_dropped['price']\n",
    "vehicles_X_train, vehicles_X_test, vehicles_y_train, vehicles_y_test = train_test_split(vehicles_X, vehicles_y, \n",
    "                                                                       test_size = 0.3,\n",
    "                                                                       random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso -- degree 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>4631.151787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>35304.618688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odometer</td>\n",
       "      <td>-78.139261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature          coef\n",
       "0       year   4631.151787\n",
       "1  cylinders  35304.618688\n",
       "2   odometer    -78.139261"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 1, include_bias = False)),\n",
    "                      ('scaler', StandardScaler()),\n",
    "                     ('lasso', Lasso(random_state = 42))])\n",
    "vehicles_pipe.fit(vehicles_X_train, vehicles_y_train)\n",
    "lasso_coefs = vehicles_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "# print(type(lasso_coefs))\n",
    "# print(lasso_coefs)\n",
    "\n",
    "\n",
    "lasso_train_mse = mean_squared_error(vehicles_y_train, vehicles_pipe.predict(vehicles_X_train))\n",
    "lasso_test_mse = mean_squared_error(vehicles_y_test, vehicles_pipe.predict(vehicles_X_test))\n",
    "var = np.var(vehicles_y_test - vehicles_pipe.predict(vehicles_X_test))\n",
    "\n",
    "# print(lasso_train_mse)\n",
    "# print(lasso_test_mse)\n",
    "# print(var)\n",
    "#Higher than variance\n",
    "\n",
    "\n",
    "feature_names = vehicles_pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "lasso_df = pd.DataFrame({'feature': feature_names, 'coef': lasso_coefs})\n",
    "\n",
    "# print(type(feature_names))\n",
    "lasso_df.loc[lasso_df['coef'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso -- degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>-56203.189950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>11411.006298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odometer</td>\n",
       "      <td>184335.417428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year^2</td>\n",
       "      <td>57157.290861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year cylinders</td>\n",
       "      <td>184294.250604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year odometer</td>\n",
       "      <td>-109717.175312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cylinders^2</td>\n",
       "      <td>-152880.337710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cylinders odometer</td>\n",
       "      <td>-75506.237636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>odometer^2</td>\n",
       "      <td>-1887.108460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature           coef\n",
       "0                year  -56203.189950\n",
       "1           cylinders   11411.006298\n",
       "2            odometer  184335.417428\n",
       "3              year^2   57157.290861\n",
       "4      year cylinders  184294.250604\n",
       "5       year odometer -109717.175312\n",
       "6         cylinders^2 -152880.337710\n",
       "7  cylinders odometer  -75506.237636\n",
       "8          odometer^2   -1887.108460"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                      ('scaler', StandardScaler()),\n",
    "                     ('lasso', Lasso(random_state = 42))])\n",
    "vehicles_pipe.fit(vehicles_X_train, vehicles_y_train)\n",
    "lasso_coefs = vehicles_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "# print(type(lasso_coefs))\n",
    "# print(lasso_coefs)\n",
    "\n",
    "\n",
    "lasso_train_mse = mean_squared_error(vehicles_y_train, vehicles_pipe.predict(vehicles_X_train))\n",
    "lasso_test_mse = mean_squared_error(vehicles_y_test, vehicles_pipe.predict(vehicles_X_test))\n",
    "var = np.var(vehicles_y_test - vehicles_pipe.predict(vehicles_X_test))\n",
    "\n",
    "# print(lasso_train_mse)\n",
    "# print(lasso_test_mse)\n",
    "# print(var)\n",
    "#Higher than variance\n",
    "\n",
    "\n",
    "feature_names = vehicles_pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "lasso_df = pd.DataFrame({'feature': feature_names, 'coef': lasso_coefs})\n",
    "\n",
    "# print(type(feature_names))\n",
    "lasso_df.loc[lasso_df['coef'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequential_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                           ('selector', SequentialFeatureSelector(LinearRegression(), \n",
    "                                                                  n_features_to_select=2)),\n",
    "                           ('linreg', LinearRegression())])\n",
    "sequential_pipe.fit(vehicles_X_train, vehicles_y_train)\n",
    "sequential_train_mse = mean_squared_error(vehicles_y_train, sequential_pipe.predict(vehicles_X_train))\n",
    "sequential_test_mse = mean_squared_error(vehicles_y_test, sequential_pipe.predict(vehicles_X_test))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "# print(sequential_train_mse)\n",
    "# print(sequential_test_mse)\n",
    "sequential_pipe\n",
    "\n",
    "# var1 = np.var(vehicles_y_train - sequential_pipe.predict(vehicles_X_train))\n",
    "# print(var1)\n",
    "var2 = np.var(vehicles_y_test - sequential_pipe.predict(vehicles_X_test))\n",
    "# print(var2)\n",
    "#Both higher than variance :c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_selector_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "#                                 ('scaler', StandardScaler()),\n",
    "#                                 ('selector', SelectFromModel(Lasso())),\n",
    "#                                     ('linreg', LinearRegression())])\n",
    "\n",
    "\n",
    "# model_selector_pipe.fit(vehicles_X_train, vehicles_y_train)\n",
    "# selector_train_mse = mean_squared_error(vehicles_y_train, model_selector_pipe.predict(vehicles_X_train))\n",
    "# selector_test_mse = mean_squared_error(vehicles_y_test, model_selector_pipe.predict(vehicles_X_test))\n",
    "\n",
    "\n",
    "\n",
    "# print(selector_train_mse)\n",
    "# print(selector_test_mse)\n",
    "\n",
    "# var2 = np.var(vehicles_y_test - model_selector_pipe.predict(vehicles_X_test))\n",
    "# print(var2)\n",
    "\n",
    "\n",
    "\n",
    "# #Test MSE is higher than variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 248923241710778.47\n",
      "Best Alpha: 10.0\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)),('scale', StandardScaler()), ('ridge', Ridge())])\n",
    "param_dict = {'ridge__alpha': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "ridge = Ridge()\n",
    "grid = GridSearchCV(ridge, param_grid=params_dict)\n",
    "grid.fit(vehicles_X_train, vehicles_y_train)\n",
    "train_preds = grid.predict(vehicles_X_train)\n",
    "test_preds = grid.predict(vehicles_X_test)\n",
    "train_mse = mean_squared_error(vehicles_y_train, train_preds)\n",
    "test_mse = mean_squared_error(vehicles_y_test, test_preds)\n",
    "\n",
    "best_alpha = grid.best_params_\n",
    "print(f'Test MSE: {test_mse}')\n",
    "print(f'Best Alpha: {list(best_alpha.values())[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>-1.971313e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>-1.000064e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>odometer</td>\n",
       "      <td>5.770596e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year^2</td>\n",
       "      <td>1.777844e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year cylinders</td>\n",
       "      <td>1.180929e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year odometer</td>\n",
       "      <td>-4.992123e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cylinders^2</td>\n",
       "      <td>-1.413034e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cylinders odometer</td>\n",
       "      <td>-7.417028e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>odometer^2</td>\n",
       "      <td>-6.745020e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature          coef\n",
       "0                year -1.971313e+05\n",
       "1           cylinders -1.000064e+06\n",
       "2            odometer  5.770596e+05\n",
       "3              year^2  1.777844e+05\n",
       "4      year cylinders  1.180929e+06\n",
       "5       year odometer -4.992123e+05\n",
       "6         cylinders^2 -1.413034e+05\n",
       "7  cylinders odometer -7.417028e+04\n",
       "8          odometer^2 -6.745020e+03"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)),('scale', StandardScaler()), ('ridge', Ridge(alpha = 10.0))])\n",
    "pipe.fit(vehicles_X_train, vehicles_y_train)\n",
    "\n",
    "ridge_coefs = pipe.named_steps['ridge'].coef_\n",
    "\n",
    "feature_names = pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "lasso_df = pd.DataFrame({'feature': feature_names, 'coef': ridge_coefs})\n",
    "\n",
    "print(type(feature_names))\n",
    "lasso_df.loc[lasso_df['coef'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV without StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)), ('ridge', Ridge())])\n",
    "# param_dict = {'ridge__alpha': [0.001, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "\n",
    "# ridge = Ridge()\n",
    "# grid = GridSearchCV(ridge, param_grid=params_dict)\n",
    "# grid.fit(vehicles_X_train, vehicles_y_train)\n",
    "# train_preds = grid.predict(vehicles_X_train)\n",
    "# test_preds = grid.predict(vehicles_X_test)\n",
    "# train_mse = mean_squared_error(vehicles_y_train, train_preds)\n",
    "# test_mse = mean_squared_error(vehicles_y_test, test_preds)\n",
    "\n",
    "# best_alpha = grid.best_params_\n",
    "# print(f'Test MSE: {test_mse}')\n",
    "# print(f'Best Alpha: {list(best_alpha.values())[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)), ('ridge', Ridge(alpha = 10.0))])\n",
    "# pipe.fit(vehicles_X_train, vehicles_y_train)\n",
    "\n",
    "# ridge_coefs = pipe.named_steps['ridge'].coef_\n",
    "\n",
    "# feature_names = pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "# lasso_df = pd.DataFrame({'feature': feature_names, 'coef': ridge_coefs})\n",
    "\n",
    "# print(type(feature_names))\n",
    "# lasso_df.loc[lasso_df['coef'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Single feature linear regression***\n",
    "* In these models, our MSE was never significantly lower than our variance, demonstrating that these models essentially predicted the mean of the given values they were analysing, giving us little insight into how non-numerical factors dynamically affect the price of used vehicles. However, analysing them may at least demonstrate to sales personnel the average value of certain features of a car, like its manufacturer or the type of fuel, which can help them asses the value of their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Re-evaluations***\n",
    "* Some models returned data that was obviously wrong, like year having a negative linreg coefficient, or odometer having a positive one. Interpreting these plainly would imply that newer cars are cheaper and that higher mileage cars are more expensive, which intuitively seems completely false.\n",
    "* **Revisiting the data preparation phase** helped us overcome these obvious disparities. One of the most influential changes was to omit data entries where the 'price' field was set to 0 or 1. These data points gave us no real insight into actual trends and were creating huge disparities in our models, and omitting them gave us much more robust information.\n",
    "* Some models were not that useful overall and their code has been commented out, but still included to indicate that they were assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Compiling new data***\n",
    "\n",
    "**Data from LASSO model (degree 1):**\n",
    "\n",
    "\n",
    "feature\tcoef\n",
    "* year\t4631.151787\n",
    "* cylinders\t35304.618688\n",
    "* odometer\t-78.139261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data from GridSearchCV model:**\n",
    "\n",
    "\n",
    "feature\tcoef\n",
    "*\tyear\t-1.971313e+05\n",
    "*\tcylinders\t-1.000064e+06\n",
    "*\todometer\t5.770596e+05\n",
    "*\tyear^2\t1.777844e+05\n",
    "*\tyear cylinders\t1.180929e+06\n",
    "*\tyear odometer\t-4.992123e+05\n",
    "*\tcylinders^2\t-1.413034e+05\n",
    "*\tcylinders odometer\t-7.417028e+04\n",
    "*\todometer^2\t-6.745020e+03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data from LASSO model (degree 2):**\n",
    "\n",
    "feature\tcoef\n",
    "* year\t-56203.189950\n",
    "* cylinders\t11411.006298\n",
    "* odometer\t184335.417428\n",
    "* year^2\t57157.290861\n",
    "* year cylinders\t184294.250604\n",
    "* year odometer\t-109717.175312\n",
    "* cylinders^2\t-152880.337710\n",
    "* cylinders odometer\t-75506.237636\n",
    "* odometer^2\t-1887.108460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single non-numeric features\n",
    "\n",
    "*Condition*\n",
    "* condition_salvage    3736.608379\n",
    "* condition_new   29779.991471\n",
    "* condition_good   33613.216880\n",
    "* condition_like new   42033.571666\n",
    "* condition_excellent   62320.623768\n",
    "* condition_fair  796604.879988\n",
    "\n",
    "*Fuel*\n",
    "* fuel_hybrid   15577.421172\n",
    "* fuel_electric   26490.500000\n",
    "* fuel_other   76943.532335\n",
    "* fuel_gas   89552.846094\n",
    "* fuel_diesel  149649.129281\n",
    "\n",
    "*Title Status*\n",
    "* title_status_salvage  10847.200115\n",
    "* title_status_missing  11993.183060\n",
    "* title_status_parts only  13648.404908\n",
    "* title_status_rebuilt  15572.034870\n",
    "* title_status_lien  22454.155684\n",
    "* title_status_clean  95358.841552"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drive*\n",
    "* drive_fwd   17324.612954\n",
    "* drive_rwd   45931.616868\n",
    "* drive_4wd  138212.830207\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Valuable takeaways***\n",
    "\n",
    "* Our analysis using the LASSO model suggest some relationships between year, cylinders, and odometer value with respect to price. It demonstrates that these are all important factors in determining price, and does not indicate that any of these values are insignificant. The cylinder value has a very high impact on price, the year value has a significant impact, and the odometer value has a slight impact -- this supports our intuition, since cylinder value can vary highly, year value may differ slightly between cars, and odometer values can be anywhere from very high to very low.\n",
    "* Car sales personnel will be happy to know that cylinder count is a huge driver of value according to the LASSO analysis, while year contributes significantly to price as it increases, and odometer value tends to gradually decrease the price of a car as it increases.\n",
    "\n",
    "* Further LASSO analysis from the degree 2 model gives us insight on how some variables interact with each other. For example, higher year values combined with higher odometer values indicate a very strong decrease in price. A similar but smaller effect can be seen with increased cylinder and odometer values. This demonstrates that greater mileage has a stronger detrimental effect on car price when occurring in newer cars and on cars with higher cylinder value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Drives the Price of a Car?: Used Car Feature to Price Analysis\n",
    "In our analysis, we used statistical techniques to analyze what drives the value of used cars. Thanks to our analysis, we can make promising conclusions about what car features contribute to their price, and how cars can be assessed to ensure that sales peronnel maintain a high value inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Non-Numeric Values\n",
    "\n",
    "Features like fuel type, condition, and title status all reliably contribute to the value of our car. Thanks to our analysis, we can pinpoint to what degree features affect price and advise sales personnel on how valuable certain features are.\n",
    "\n",
    "### Condition\n",
    "* Our analysis demonstrates that \"fair\" and \"excellent\" condition for cars are massive drivers of value. These features heavily increase the selling price of a car. Cars with a \"like new\" condition are actually statistically not as strongly preferred in the used car market, and \"new\" cars even less so, demonstrating buyer's preferences towards previously used cars and a likelihood for less costly brands to be present in inventory space. ***Used car sales personnel should prioritize \"fair\" and \"excellent\" cars** most to align with consumer interest, followed by \"like new\" and \"good\", then by \"new\" and \"salvage\"*\n",
    "\n",
    "\n",
    "### Drive\n",
    "* Amongst cars designated with front-wheel drive (FWD), rear-wheel drive (RWD), and four-wheel drive (4WD), 4WD is by far the biggest contributer to value. A vehicle's 4WD designation tends to contribute nearly three times as much towards a car's price than a FWD designation, and far far more than a RWD designation. ***Used car sales personnel should prioritize 4WD in ther inventory** and then provide FWD, followed by RWD vehicles in order to maximize the price of their stock*\n",
    "\n",
    "\n",
    "### Fuel\n",
    "* In terms of fuel type, sales personnel can **expect diesel and gas cars to be the highest price vehicles on their lot**. Vehicles with an \"other\" designation are less valuable, while **electric and hybrid vehicles are even further less valuable** according to analysis. This likely reflects the used car market, where users are hoping for reliable cars for every day use, and may not have the capability to use electric means of fuel.\n",
    "\n",
    "### Title Status\n",
    "* In terms of title status, sales personnel can rest assured that intuitively, the better condition a title status of a car, the higher the price the car will be. In essence, **clean title status indicates highest pricing, then lien**, followed by rebuilt, parts only, missing, and salvage respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Values\n",
    "\n",
    "### Cylinders, Odometer, Year\n",
    "\n",
    "* Our analysis provides promising information about the numeric features of car's in the inventory of our sales personnel. Firstly, ** increasing cylinder count has a very strong effect on price**, where each increase in cylinder count increases the price of a car greatly. **Sales personnel should prioritize higher cylinder count cars** to ensure greater pricing. **Cars newer by the year are more valuable**, where each increase in year leads to a moderate increase in price. **Sales personnel should stock up on newer car models** to maximize their pricing. Finally, odometer count gradually decreases price as it increases. Unsurprisingly **sales personnel should be aware that greater mileage lowers the price of a car**, considering lower mileage cars to maximize value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
